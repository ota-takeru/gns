

## gns(graph network based simulators)とは
流体、剛体、変形可能な物質などの相互作用をシミュレーションすることができる機械学習フレームワーク。  

入力には各粒子の状態（位置、速度）を受け取り、1ステップ先の加速度を出力する。教師データは各粒子の加速度が与えられるので、その値に近づくように学習する。   

### 具体的なモデル構造
各時間ステップに対して以下の処理を行う。    
**encoder**    
各粒子に対して、近傍の粒子間にエッジを張る。  
すべてのノードとエッジをMLPで潜在ベクトルに変換する。  
**processor**  
各エッジを自身のエッジと、接続しているノードを入力として更新する。  
各ノードを自身のノードと、接続している更新されたエッジを入力として更新する。  
**decoder**  
MLPを使って各ノードのベクトルを加速度に変換する。   
**学習**   
粒子をランダムにサンプリングし加速度に対する損失が小さくなるようにパラメータを更新する。  

### gnsの良い点  
ノード特徴に物質のフラグを入れることで、単一のモデルで複数の物質を扱うことができる。  
近傍をメッセージパッシングするという構造が、物理における局所相互作用性を反映している。  
従来のニューラルネットワークベースのものに比べて精度と汎化が良い。  

### gnsの課題
長い時間予測すると誤差が蓄積する。  
特に粒子数を増やしていくと推論時間が従来の手法よりも長くなりやすい。  

gnsの課題であるロールアウトによる誤差の蓄積を解決するために新しい手法を考える。    
今回は対象を絞るために流体を扱う。  

## SPH法
教師データの作成にはgnsと同じように、流体を粒子の集合として扱うsph法を採用する。  

### 具体的な手法
流体力学において以下の基礎方程式について解く必要がある。  
[具体的な式を書く]    
連続の式      
運動方程式   
状態方程式（圧力の式）  
圧力は扱う流体によって異なる定義がある。今回は水に近い非圧縮流体を考える。  

sph法は以下の式で定義される。  
密度の定義  
運動方程式の定義  

これは流体力学の基礎方程式に対して、カーネル近似と積分の離散化を行った形と一致している。  

流体の力は大きく保存力と散逸に分けられる。  
保存力は圧力や重力など位置や密度に依存し、ポテンシャルエネルギーの勾配で表される。    
$a = - \nabla_x U(x) / m$        
- $U$ ポテンシャルエネルギー     

散逸は粘性や摩擦などによるもので速度に依存し、運動エネルギーを減らしていく方向に働く。  

このようなバイアスをgnsに組み込むことで長期ロールアウトによる誤差の蓄積を抑える手法を次で提案する。  

## 提案する手法
gnsによる出力を加速度ではなく、保存力と散逸を計算する形にする。  

### 具体的な手法
gnsと同じ構造を用いてポテンシャルエネルギーと、散逸による加速度を別々に出力する。  
水を想定して弱圧縮流体を扱う。  
 
**保存力**
位置を引数にポテンシャルエネルギーを出力する。  
出力されたポテンシャルエネルギーを各方向成分に対して偏微分することで加速度を求める。    
ポテンシャルエネルギーの計算はニューラルネットワークの関数とみることができて、pytorchの自動微分を用いて偏微分を計算する。  
**散逸**
相対速度を引数に散逸による加速度を出力する。  
散逸による加速度は運動エネルギーが増えないように設計する。  

そのあとは、加速度を合計してgnsと同じように学習を進める。  


ポテンシャルエネルギーから偏微分できるものだけに限定されるので、仮説空間を狭めることができる。  
自由度をポテンシャルエネルギーと散逸それぞれで制限しつつ、エネルギーが勝手に作られないようにすることで、長期のロールアウト誤差の減少が期待できる。  

### 結果
元論文のgnsと比較する。  
1ステップとロールアウトの誤差を比べる。  
横軸タイムステップ、縦軸位置誤差。 
パラメータ数や計算量をそろえる。  
保存力と散逸部分の加速度を教師データと比較してちゃんとバイアスが効いているか確かめる。  
散逸によって減るエネルギーを考慮して総エネルギーが増減しないか確かめる。  

### 今後の課題  
流体だけ扱ったので複数の物質をどこまで扱えるのか。 
計算時間の短縮。  
