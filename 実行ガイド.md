# GNS プロジェクト実行ガイド

このガイドでは、学習データの生成から学習、rollout までの一連の実行方法を説明します。

## 目次

1. [環境セットアップ](#1-環境セットアップ)
2. [学習データの生成](#2-学習データの生成)
3. [モデルの学習](#3-モデルの学習)
4. [Rollout（推論）の実行](#4-rollout推論の実行)
5. [可視化と結果の確認](#5-可視化と結果の確認)

---

## 1. 環境セットアップ

このプロジェクトは`uv`を使用してパッケージを管理しています。

### 必要なツール

- Python 3.10 以上
- uv（パッケージマネージャー）
- CUDA 対応 GPU（推奨、CPU でも動作可能）

### 依存パッケージのインストール

```bash
# uvを使って依存パッケージをインストール
uv sync
```

---

## 2. 学習データの生成

### 2.1 データ生成スクリプトの実行

学習データは`pymunk`物理エンジンを使用して生成します。

```bash
# データ生成スクリプトを実行
uv run python datasets/scripts/gen_pymunk.py
```

### 2.2 生成されるデータ

実行すると、以下のファイルが`datasets/out/`ディレクトリに生成されます:

- **train.npz**: 訓練データ（デフォルト 1000 シーン）
- **valid.npz**: 検証データ（デフォルト 100 シーン）
- **metadata.json**: データセットのメタ情報（速度・加速度の統計、接続半径など）
- **train/scene\_\*.npz**: 個別シーンのデータ（オプショナル）
- **valid/scene\_\*.npz**: 個別シーンのデータ（オプショナル）

### 2.3 データ生成のカスタマイズ

`datasets/scripts/gen_pymunk.py`を編集して、以下のパラメータを調整できます:

```python
# 訓練シーン数（308行目付近）
num_train_scenes = 1000  # この値を変更

# 検証シーン数（328行目付近）
num_valid_scenes = 100   # この値を変更。。

# シーン生成パラメータ（generate_scene関数、113行目）
def generate_scene(
    T=240,              # タイムステップ数
    dt=1/120,           # 時間刻み
    substeps=4,         # サブステップ数
    n_bodies=(2, 5),    # 剛体数の範囲
    density=16          # 粒子サンプリング密度
):
```

### 2.4 データの内容

各シーンには以下が含まれます:

- **剛体オブジェクト**: ランダムな形状（箱または円）が落下
- **壁**: 床、左壁、右壁（STATIC ボディとして固定）
- **物理パラメータ**: 質量、摩擦、反発係数などがランダム化

---

## 3. モデルの学習

### 3.1 設定ファイルの確認

学習設定は`config.yaml`で管理されています:

```yaml
mode: train
data_path: ./datasets/out/
model_path: ./models/
batch_size: 2
noise_std: 0.00067
ntraining_steps: 100 # 学習ステップ数
validation_interval: null # 検証間隔（nullで無効）
nsave_steps: 50 # モデル保存間隔
lr_init: 0.0001 # 初期学習率
lr_decay: 0.1 # 学習率減衰率
lr_decay_steps: 5000000 # 減衰ステップ数
```

### 3.2 学習の実行

```bash
# 学習を実行
uv run python src/train.py --config config.yaml
```

### 3.3 学習の進行

学習中は以下のような出力が表示されます:

```
device: cuda:0
epoch=0 step=0/100 loss=0.123456 lr=1.000000e-04
epoch=0 step=1/100 loss=0.098765 lr=9.999980e-05
...
```

### 3.4 保存されるファイル

学習中、`models/`ディレクトリに以下が保存されます:

- **model-{step}.pt**: モデルの重み（nsave_steps 毎）
- **train_state-{step}.pt**: オプティマイザ状態と学習履歴
- **used_config.json**: 使用された設定の記録

### 3.5 学習の再開

学習を中断した場合、設定ファイルで再開できます:

```yaml
model_file: latest # 最新のモデルを読み込む
train_state_file: latest # 最新の学習状態を読み込む
```

### 3.6 学習パラメータの調整

実際の学習では、より多くのステップが必要です:

```yaml
ntraining_steps: 20000000 # 2000万ステップ（推奨）
validation_interval: 5000 # 5000ステップごとに検証
nsave_steps: 5000 # 5000ステップごとに保存
```

---

## 4. Rollout（推論）の実行

### 4.1 Rollout 設定ファイルの確認

推論用の設定は`config_rollout.yaml`にあります:

```yaml
mode: rollout
data_path: ./datasets/out/
model_path: ./models/
output_path: ./rollouts/
model_file: latest # 最新の学習済みモデルを使用
```

### 4.2 推論の実行方法

#### 方法 1: スクリプトを使用（推奨）

```bash
# 推論から可視化まで一括実行
bash run_inference.sh
```

このスクリプトは以下を自動で実行します:

1. Rollout（推論）の実行
2. 結果の分析（analyze_rollouts.py）
3. HTML ファイルへの可視化（visualize_rollout.py）

#### 方法 2: 手動実行

```bash
# 1. Rolloutの実行
uv run python src/train.py --config config_rollout.yaml

# 2. 結果の分析
uv run python analyze_rollouts.py

# 3. 可視化（各rolloutファイルに対して）
uv run python visualize_rollout.py rollouts/rollout_ex0.pkl --output rollouts/rollout_ex0.html --html
```

### 4.3 Rollout の出力

`rollouts/`ディレクトリに以下が生成されます:

- **rollout_ex{i}.pkl**: 各例の推論結果（pickle ファイル）
  - `initial_positions`: 初期 6 ステップの位置
  - `predicted_rollout`: モデルの予測軌跡
  - `ground_truth_rollout`: 正解軌跡
  - `particle_types`: 粒子タイプ
  - `loss`: 予測誤差

---

## 5. 可視化と結果の確認

### 5.1 HTML 可視化の確認

`run_inference.sh`を実行した場合、`rollouts/`ディレクトリに HTML ファイルが生成されます:

```
rollouts/
  ├── rollout_ex0.html
  ├── rollout_ex1.html
  └── ...
```

これらのファイルをブラウザで開くと、アニメーションで結果を確認できます。

### 5.2 可視化の見方

- **青色の軌跡**: モデルの予測
- **赤色の軌跡**: 正解（物理シミュレーション）
- **スライダー**: タイムステップを移動
- **再生ボタン**: アニメーション再生

### 5.3 分析結果の確認

`analyze_rollouts.py`を実行すると、以下の統計情報が表示されます:

```
=== Rollout 結果分析 ===
ファイル数: 10

統計情報:
  平均ロス: 0.0123
  最小ロス: 0.0098
  最大ロス: 0.0156
  標準偏差: 0.0012
```

---

## 全体のワークフロー

```mermaid
graph TD
    A[1. データ生成] --> B[datasets/out/*.npz]
    B --> C[2. モデル学習]
    C --> D[models/model-*.pt]
    D --> E[3. Rollout実行]
    E --> F[rollouts/*.pkl]
    F --> G[4. 可視化]
    G --> H[rollouts/*.html]
```

### 簡単な実行手順

```bash
# ステップ1: データ生成
uv run python datasets/scripts/gen_pymunk.py

# ステップ2: 学習（短時間テスト）
uv run python src/train.py --config config.yaml

# ステップ3: 推論と可視化
bash run_inference.sh
```

---

## トラブルシューティング

### Q1: `FileNotFoundError: No model files found`

**原因**: 学習が完了していない、またはモデルファイルが存在しない

**解決策**:

```bash
# 学習を実行してモデルを生成
uv run python src/train.py --config config.yaml
```

### Q2: GPU メモリ不足エラー

**原因**: バッチサイズが大きすぎる

**解決策**: `config.yaml`の batch_size を減らす

```yaml
batch_size: 1 # 2から1に変更
```

### Q3: データが見つからない

**原因**: データ生成が完了していない

**解決策**:

```bash
# データ生成を実行
uv run python datasets/scripts/gen_pymunk.py

# データの存在確認
ls -l datasets/out/
```

### Q4: 学習が進まない

**原因**: 学習率が低すぎる、またはデータが不足

**解決策**:

- データ量を増やす（gen_pymunk.py の num_train_scenes を増やす）
- 学習率を調整する（config.yaml の lr_init を調整）

---

## 推奨設定

### 本格的な学習を行う場合

```yaml
# config.yaml
mode: train
ntraining_steps: 20000000 # 2000万ステップ
batch_size: 4 # GPUメモリに応じて調整
validation_interval: 5000
nsave_steps: 5000
```

### データ生成の推奨設定

```python
# datasets/scripts/gen_pymunk.py
num_train_scenes = 5000     # より多くの訓練データ
num_valid_scenes = 500      # より多くの検証データ
```

---

## 参考ファイル

- **論文実装検証レポート.md**: 実装の詳細と検証結果
- **推論結果サマリー.md**: Rollout 結果の詳細分析
- **可視化結果の見方.md**: 可視化ファイルの詳しい見方
- **INFERENCE_GUIDE.md**: 推論実行の詳細ガイド

---

## まとめ

このプロジェクトは以下の 3 ステップで実行できます:

1. **データ生成**: `uv run python datasets/scripts/gen_pymunk.py`
2. **学習**: `uv run python src/train.py --config config.yaml`
3. **推論**: `bash run_inference.sh`

各ステップの設定は対応する YAML ファイルや Python スクリプトで調整可能です。
