# GNS プロジェクト実行ガイド

このガイドでは、学習データの生成から学習、rollout までの一連の実行方法を説明します。

## 目次

1. [環境セットアップ](#1-環境セットアップ)
2. [学習データの生成](#2-学習データの生成)
3. [モデルの学習](#3-モデルの学習)
4. [Rollout（推論）の実行](#4-rollout推論の実行)
5. [可視化と結果の確認](#5-可視化と結果の確認)

---

## 1. 環境セットアップ

このプロジェクトは`uv`を使用してパッケージを管理しています。

### 必要なツール

- Python 3.10 以上
- uv（パッケージマネージャー）
- CUDA 対応 GPU（推奨、CPU でも動作可能）

### 依存パッケージのインストール

```bash
# uvを使って依存パッケージをインストール
uv sync
```

---

## 2. 学習データの生成

### 2.1 剛体シーンの生成（pymunk）

剛体落下シーンは`pymunk`物理エンジンで生成します。

```bash
# 剛体データセットの生成
uv run python datasets/scripts/gen_pymunk.py
```

設定は`datasets/config.yaml`にまとめてあります。粒子密度や出力先を変えたい場合はこのファイルを編集してください（スクリプト本体を直接変更する必要はありません）。

### 2.2 流体シーンの生成（PySPH）

流体の学習データは PySPH を用いた SPH シミュレーションで生成します。1回の実行で複数ケースをまとめて出力でき、ケースごとに専用ディレクトリが作成されるため既存の剛体データと共存できます。

```bash
# 流体データセットの生成（デフォルト設定）
uv run python datasets/scripts/gen_fluid.py
```

- 既定の設定ファイル: `datasets/config/fluid.yaml`（PySPH 向けのパラメータを含む）
- `cases`配列にケース名・パラメータを列挙すると、それぞれが`output_root/<case_name>/`以下に保存されます。
- 例: `dam_break_left`と`dam_break_right`を同時に生成 → `datasets/out_fluid/dam_break_left/`, `datasets/out_fluid/dam_break_right/`
- PySPH が未インストールの場合は `pip install pysph` を実行してから生成してください。

学習時に利用するケースは `config.yaml` の `scenario` フィールドで選択できます（詳細は [3.1 設定ファイルの確認](#31-設定ファイルの確認) を参照）。

### 2.3 生成されるデータ

どちらのスクリプトも、各ケース（または既定ディレクトリ）に下記ファイル／フォルダを生成します:

- **train.npz / valid.npz / test.npz**: 学習・検証・推論用のまとめファイル
- **metadata.json**: 速度・加速度統計、接続半径、境界情報などのメタデータ
- **train/scene\_\*.npz・valid/scene\_\*.npz**: 個別シーンの軌跡（必要に応じて解析可能）

複数ケースを同時に保持したい場合は、それぞれの出力ディレクトリを残しておき、学習時に読みたいケースを `config.yaml` の `scenario` / `scenario_options` で切り替えます。

### 2.4 データ生成のカスタマイズ

- 剛体シーン: `datasets/config.yaml`
- 流体シーン: `datasets/config/fluid.yaml`

主な調整項目:

- `num_train_scenes` / `num_valid_scenes`: シーン数
- `timesteps`, `dt`, `substeps`（または`solver_substeps`）: 時間分解能
- 剛体: `rigid_count_range`, `particle_density` など
- 流体: `particle_spacing`, `kernel_radius_scale`, `stiffness`, `viscosity`, `cases[n].emitter` など
- `output_dir` / `output_root`: 出力先

剛体では粒子密度を、流体では粒子間隔とカーネル半径を調整することで粒子数と表現力をコントロールできます。値を詰めすぎると生成に時間が掛かるため、段階的に試すのが安全です。

### 2.5 データの内容

- 剛体シーン: ランダム形状の剛体が落下し、床・左右壁と相互作用します。
- 流体シーン: SPH 粒子で構成された流体塊がケースごとの境界内で挙動します（ダムブレーク、スロッシングなど）。

---

## 3. モデルの学習

### 3.1 設定ファイルの確認

学習設定は`config.yaml`で管理されています:

```yaml
mode: train
data_path: ./datasets/out/
scenario: rigid              # rigid / fluid など
scenario_options:
  rigid:
    dataset: ./datasets/out
  fluid:
    dataset: ./datasets/out_fluid/dam_break_left
    rollout_dataset: valid
model_path: ./models/
tensorboard_log_dir: null      # nullなら model_path/tb を使用
tensorboard_port: null         # 任意のポートに自動割当
tensorboard_host: null         # デフォルトは 127.0.0.1
batch_size: 2
noise_std: 0.00067
ntraining_steps: 100 # 学習ステップ数
validation_interval: null # 検証間隔（nullで無効）
nsave_steps: 50 # モデル保存間隔
log_interval: 10           # 何ステップごとに軽量ログを出力するか
tensorboard_interval: 10   # TensorBoard に書き込むステップ間隔(null で log_interval と同じ)
rollout_interval: null        # ロールアウト評価を無効化したい場合は null
rollout_max_examples: 1       # 評価に使うサンプル数
rollout_dataset: null         # null は valid/test/train の順で自動選択
train_dataset_fraction: null  # 学習データを一部のみ使う場合は 0-1 の値を設定
valid_dataset_fraction: null  # 検証データを一部のみ使う場合は 0-1 の値を設定
train_dataset_count: null     # 学習データの使用件数を直接指定（優先度: count > fraction）
valid_dataset_count: null     # 検証データの使用件数を直接指定（優先度: count > fraction）
lr_init: 0.0001 # 初期学習率
lr_decay: 0.1 # 学習率減衰率
lr_decay_steps: 5000000 # 減衰ステップ数
```

`scenario`により使用するデータセットを簡単に切り替えられます。`scenario_options` の項目を追加すれば、新しいケース（例: `fluid_high_res`）を登録し、`scenario: fluid_high_res` と書き換えるだけで学習対象を変更できます。個別にパラメータを変えたい場合は `overrides` を指定して `batch_size` や `noise_std` などをシナリオごとに上書きできます。

### 3.2 学習の実行

```bash
# 学習を実行
uv run python src/train.py --config config.yaml
```

### 3.3 学習の進行

学習中は以下のような出力が表示されます:

```
device: cuda:0
TensorBoard logging to /abs/path/to/models/tb/run-20240601-120000
TensorBoard available at http://127.0.0.1:6006/
epoch=0 step=0/100 loss=0.123456 lr=1.000000e-04 grad_norm=2.3456 eta=12:34
epoch=0 step=1/100 loss=0.098765 lr=9.999980e-05 grad_norm=2.1234 eta=12:33
...
```

表示された URL にアクセスすると、TensorBoard で `train/loss` や `rollout/rmse_mean` などのグラフをリアルタイムで確認できます。URL が表示されない場合でも、以下のコマンドで手動起動できます（`logdir` はログディレクトリに合わせて変更してください）。

```bash
tensorboard --logdir ./models/tb
```

`log_interval` を変更すると、学習中にコンソールへ表示する軽量ログ（train loss、学習率など）の出力間隔を調整できます。頻繁にし過ぎるとログが読みづらくなるため、通常は 10〜100 ステップ程度が目安です。`tensorboard_interval` は TensorBoard への書き込み頻度を制御し、null の場合は `log_interval` と同じ間隔で出力します。リソース負荷を抑えるため、こちらも過度に小さな値にしないようにしましょう。

`rollout_interval` を null 以外に設定すると、指定ステップごとにロールアウト推定を実行し、`rollout/rmse_mean`・`rollout/rmse_last`・`rollout/instability` が TensorBoard に記録されます。`rollout_dataset` で評価用データ（`valid`/`test`/`train`）を明示でき、`rollout_max_examples` でサンプル数を調整できます（大きくすると評価時間は延びます）。

`train_dataset_fraction` や `valid_dataset_fraction` を 0〜1 の範囲で指定すると、対応するデータセットの先頭何割かだけを使用して学習・検証します。また `train_dataset_count` / `valid_dataset_count` を設定すると、使用する軌跡数を直接指定できます（count が指定されている場合は fraction より優先されます）。null のままなら全データを利用します。早い試行やデバッグに便利です。

### 3.4 保存されるファイル

学習中、`models/`ディレクトリに以下が保存されます:

- **model-{step}.pt**: モデルの重み（nsave_steps 毎）
- **train_state-{step}.pt**: オプティマイザ状態と学習履歴
- **used_config.json**: 使用された設定の記録

### 3.5 学習の再開

学習を中断した場合、設定ファイルで再開できます:

```yaml
model_file: latest # 最新のモデルを読み込む
train_state_file: latest # 最新の学習状態を読み込む
```

### 3.6 学習パラメータの調整

実際の学習では、より多くのステップが必要です:

```yaml
ntraining_steps: 20000000 # 2000万ステップ（推奨）
validation_interval: 5000 # 5000ステップごとに検証
nsave_steps: 5000 # 5000ステップごとに保存
```

---

## 4. Rollout（推論）の実行

### 4.1 Rollout 設定ファイルの確認

推論用の設定は`config_rollout.yaml`にあります:

```yaml
mode: rollout
data_path: ./datasets/out/
model_path: ./models/
output_path: ./rollouts/
model_file: latest # 最新の学習済みモデルを使用
```

### 4.2 推論の実行方法

#### 方法 1: スクリプトを使用（推奨）

```bash
# 推論から可視化まで一括実行
bash run_inference.sh
```

このスクリプトは以下を自動で実行します:

1. Rollout（推論）の実行
2. 結果の分析（analyze_rollouts.py）
3. HTML ファイルへの可視化（visualize_rollout.py）

#### 方法 2: 手動実行

```bash
# 1. Rolloutの実行
uv run python src/train.py --config config_rollout.yaml

# 2. 結果の分析
uv run python analyze_rollouts.py

# 3. 可視化（各rolloutファイルに対して）
uv run python visualize_rollout.py rollouts/rollout_ex0.pkl --output rollouts/rollout_ex0.html --html
```

### 4.3 Rollout の出力

`rollouts/`ディレクトリに以下が生成されます:

- **rollout_ex{i}.pkl**: 各例の推論結果（pickle ファイル）
  - `initial_positions`: 初期 6 ステップの位置
  - `predicted_rollout`: モデルの予測軌跡
  - `ground_truth_rollout`: 正解軌跡
  - `particle_types`: 粒子タイプ
  - `loss`: 予測誤差

---

## 5. 可視化と結果の確認

### 5.1 HTML 可視化の確認

`run_inference.sh`を実行した場合、`rollouts/`ディレクトリに HTML ファイルが生成されます:

```
rollouts/
  ├── rollout_ex0.html
  ├── rollout_ex1.html
  └── ...
```

これらのファイルをブラウザで開くと、アニメーションで結果を確認できます。

### 5.2 可視化の見方

- **青色の軌跡**: モデルの予測
- **赤色の軌跡**: 正解（物理シミュレーション）
- **スライダー**: タイムステップを移動
- **再生ボタン**: アニメーション再生

### 5.3 分析結果の確認

`analyze_rollouts.py`を実行すると、以下の統計情報が表示されます:

```
=== Rollout 結果分析 ===
ファイル数: 10

統計情報:
  平均ロス: 0.0123
  最小ロス: 0.0098
  最大ロス: 0.0156
  標準偏差: 0.0012
```

---

## 全体のワークフロー

```mermaid
graph TD
    A[1. データ生成] --> B[datasets/out/*.npz]
    B --> C[2. モデル学習]
    C --> D[models/model-*.pt]
    D --> E[3. Rollout実行]
    E --> F[rollouts/*.pkl]
    F --> G[4. 可視化]
    G --> H[rollouts/*.html]
```

### 簡単な実行手順

```bash
# ステップ1: データ生成
uv run python datasets/scripts/gen_pymunk.py

# ステップ2: 学習（短時間テスト）
uv run python src/train.py --config config.yaml

# ステップ3: 推論と可視化
bash run_inference.sh
```

---

## トラブルシューティング

### Q1: `FileNotFoundError: No model files found`

**原因**: 学習が完了していない、またはモデルファイルが存在しない

**解決策**:

```bash
# 学習を実行してモデルを生成
uv run python src/train.py --config config.yaml
```

### Q2: GPU メモリ不足エラー

**原因**: バッチサイズが大きすぎる

**解決策**: `config.yaml`の batch_size を減らす

```yaml
batch_size: 1 # 2から1に変更
```

### Q3: Kaggle で `No model files found in /kaggle/working/.../models` が出る

- `models/` ディレクトリは `.gitignore` のため、リポジトリだけをアップロードすると学習済みモデルが含まれません
- 事前にローカルで `models/run-*/model-*.pt` を含む zip を作り、Kaggle の **Add data** で `/kaggle/input/<データセット名>/models/` に置く
- ノートブック先頭で下記のいずれかを実行する

```bash
# 1) モデルを作業ディレクトリにコピー
cp -r /kaggle/input/<データセット名>/models ./models

# 2) もしくは config_rollout.yaml の model_path を直接差し替え
sed -i 's|^model_path: .*|model_path: /kaggle/input/<データセット名>/models/|' config_rollout.yaml
```

- `model_file: latest` のままで `/models/run-*/model-*.pt` があれば自動検出されます

### Q3: データが見つからない

**原因**: データ生成が完了していない

**解決策**:

```bash
# データ生成を実行
uv run python datasets/scripts/gen_pymunk.py

# データの存在確認
ls -l datasets/out/
```

### Q4: 学習が進まない

**原因**: 学習率が低すぎる、またはデータが不足

**解決策**:

- データ量を増やす（gen_pymunk.py の num_train_scenes を増やす）
- 学習率を調整する（config.yaml の lr_init を調整）

---

## 推奨設定

### 本格的な学習を行う場合

```yaml
# config.yaml
mode: train
ntraining_steps: 20000000 # 2000万ステップ
batch_size: 4 # GPUメモリに応じて調整
validation_interval: 5000
nsave_steps: 5000
```

### データ生成の推奨設定

```python
# datasets/scripts/gen_pymunk.py
num_train_scenes = 5000     # より多くの訓練データ
num_valid_scenes = 500      # より多くの検証データ
```

---

## 参考ファイル

- **論文実装検証レポート.md**: 実装の詳細と検証結果
- **推論結果サマリー.md**: Rollout 結果の詳細分析
- **可視化結果の見方.md**: 可視化ファイルの詳しい見方
- **INFERENCE_GUIDE.md**: 推論実行の詳細ガイド

---

## まとめ

このプロジェクトは以下の 3 ステップで実行できます:

1. **データ生成**: `uv run python datasets/scripts/gen_pymunk.py`
2. **学習**: `uv run python src/train.py --config config.yaml`
3. **推論**: `bash run_inference.sh`

各ステップの設定は対応する YAML ファイルや Python スクリプトで調整可能です。
### 4.4 推論時に可視化するシーン数の制御

推論（rollout）時に生成する pkl（＝可視化対象）を上限 N 件に制限できます。`config_rollout.yaml` に以下を追加または編集してください。

```
# 推論時に保存するシーン数の上限（null で全件）
rollout_inference_max_examples: 3
```

これにより `rollouts/rollout_ex{i}.pkl` の生成が先頭 N 件に制限され、可視化対象もその範囲になります。
