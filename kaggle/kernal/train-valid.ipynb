{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3052e14e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "# Kaggle の入力データセット slug（username/slug の slug 部分）をセット\n",
    "DATASET_SLUG = 'gns-codes'  # 変更する場合はここを更新\n",
    "DATASET_ROOT = Path(f'/kaggle/input/{DATASET_SLUG}')\n",
    "WORK_ROOT = Path('/kaggle/working')\n",
    "repo_dir = WORK_ROOT / 'code'\n",
    "\n",
    "code_dir = DATASET_ROOT / 'code'\n",
    "code_zip = DATASET_ROOT / 'code.zip'\n",
    "\n",
    "# 取得優先順位: 展開済み code/ があればそれを使う。無ければ code.zip を展開。どちらも無ければエラー。\n",
    "if code_dir.exists():\n",
    "    src = code_dir\n",
    "elif code_zip.exists():\n",
    "    if repo_dir.exists():\n",
    "        shutil.rmtree(repo_dir)\n",
    "    with zipfile.ZipFile(code_zip) as zf:\n",
    "        zf.extractall(repo_dir)\n",
    "    src = repo_dir\n",
    "else:\n",
    "    raise FileNotFoundError(f\"/kaggle/input/{DATASET_SLUG} に code ディレクトリも code.zip も見つかりません。Add Data で {DATASET_SLUG} を追加してください。\")\n",
    "\n",
    "if src != repo_dir:\n",
    "    if repo_dir.exists():\n",
    "        shutil.rmtree(repo_dir)\n",
    "    shutil.copytree(src, repo_dir)\n",
    "# unzip でサブディレクトリ1階層挟まった場合に平坦化\n",
    "if repo_dir.exists():\n",
    "    children = list(repo_dir.iterdir())\n",
    "    if len(children)==1 and children[0].is_dir():\n",
    "        inner = children[0]\n",
    "        for path in inner.iterdir():\n",
    "            path.rename(repo_dir / path.name)\n",
    "        inner.rmdir()\n",
    "%cd $repo_dir\n",
    "# 依存パッケージは Kaggle 環境の標準ライブラリを利用（追加インストールなし）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b639fae4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install torch-geometric \n",
    "# torch-scatter torch-sparse torch-cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac806101",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch_ver = torch.__version__.split(\"+\")[0]          # 例: \"2.1.0+cu121\" -> \"2.1.0\"\n",
    "cuda_ver  = torch.version.cuda                      # 例: \"12.1\" / CPUなら None\n",
    "cuda_tag  = \"cpu\" if cuda_ver is None else \"cu\" + cuda_ver.replace(\".\", \"\")\n",
    "\n",
    "url = f\"https://data.pyg.org/whl/torch-{torch_ver}+{cuda_tag}.html\"\n",
    "print(\"PyG wheels:\", url)\n",
    "\n",
    "# 必要なやつだけ入れる（radius_graphなら torch_cluster が本体）\n",
    "!pip -q install torch-cluster -f {url}\n",
    "\n",
    "# もし他も使うならまとめて\n",
    "# !pip -q install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f {url}\n",
    "# !pip -q install torch_geometric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c2ee7f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "REPO = Path('/kaggle/working/code')\n",
    "cfg_path = REPO / 'config.yaml'\n",
    "\n",
    "with cfg_path.open('r', encoding='utf-8') as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "cfg['method'] = 'gns'\n",
    "cfg.setdefault('method_options', {}).setdefault('gns', {})['edge_relative_velocity'] = True\n",
    "cfg['amp_enable'] = False\n",
    "cfg['ntraining_steps'] = 100\n",
    "cfg['train_dataset_count'] = 50\n",
    "cfg['valid_dataset_count'] = 10\n",
    "cfg['validation_interval'] = 1000\n",
    "cfg['max_grad_norm'] = 100\n",
    "max_steps_cap = 70  # 学習・検証・ロールアウト評価の上限ステップ数\n",
    "cfg['train_max_steps_per_trajectory'] = max_steps_cap\n",
    "cfg['valid_max_steps_per_trajectory'] = max_steps_cap\n",
    "cfg['rollout_max_steps'] = max_steps_cap\n",
    "\n",
    "# Kaggle 入力データセットのパスに合わせて上書き\n",
    "dataset_root = '/kaggle/input/dam-break-left-slosh2'\n",
    "cfg['data_path'] = dataset_root\n",
    "cfg.setdefault('scenario_options', {}).setdefault('fluid', {})['dataset'] = dataset_root\n",
    "\n",
    "with cfg_path.open('w', encoding='utf-8') as f:\n",
    "    yaml.safe_dump(cfg, f, allow_unicode=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2ee5b6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%cd /kaggle/working/code\n",
    "\n",
    "import subprocess\n",
    "import torch\n",
    "\n",
    "gpu_count = torch.cuda.device_count()\n",
    "if gpu_count >= 2:\n",
    "    nproc = 2\n",
    "    cmd = [\"torchrun\", f\"--nproc_per_node={nproc}\", \"src/train.py\", \"--config\", \"config.yaml\"]\n",
    "elif gpu_count == 1:\n",
    "    nproc = 1\n",
    "    cmd = [\"python\", \"src/train.py\", \"--config\", \"config.yaml\"]\n",
    "else:\n",
    "    nproc = 0\n",
    "    cmd = [\"python\", \"src/train.py\", \"--config\", \"config.yaml\"]\n",
    "    print(\"GPU が検出できませんでした。CPU で実行します。\")\n",
    "\n",
    "print(f\"検出GPU数: {gpu_count} -> 実行コマンド: {' '.join(cmd)}\")\n",
    "subprocess.run(cmd, check=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850e27e6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "REPO = Path('/kaggle/working/code')\n",
    "cfg_path = REPO / 'config_rollout.yaml'\n",
    "\n",
    "with cfg_path.open('r', encoding='utf-8') as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "cfg['method'] = 'gns'\n",
    "cfg.setdefault('method_options', {}).setdefault('gns', {})['edge_relative_velocity'] = True\n",
    "cfg['rollout_inference_max_examples'] = 1\n",
    "max_steps_cap = 70  # 学習と同じ上限で推論ロールアウトを制限\n",
    "cfg['train_max_steps_per_trajectory'] = max_steps_cap\n",
    "cfg['valid_max_steps_per_trajectory'] = max_steps_cap\n",
    "cfg['rollout_max_steps'] = max_steps_cap\n",
    "\n",
    "# 推論時のデータセットパスを上書き\n",
    "dataset_root = '/kaggle/input/dam-break-left-slosh2'\n",
    "cfg.setdefault('scenario_options', {}).setdefault('fluid', {})['dataset'] = dataset_root\n",
    "\n",
    "with cfg_path.open('w', encoding='utf-8') as f:\n",
    "    yaml.safe_dump(cfg, f, allow_unicode=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9d5fdf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%cd /kaggle/working/code\n",
    "!python src/train.py --config config_rollout.yaml\n",
    "!python analyze_rollouts.py\n",
    "!python visualize_rollout.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f292425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dam_break_left valid 用の推論設定をノートブック内で組み立て（ファイル出力なし）\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from train_config import Config\n",
    "\n",
    "REPO = Path('/kaggle/working/code')\n",
    "cfg_src = REPO / 'config_rollout.yaml'\n",
    "\n",
    "dataset_root = REPO / 'datasets/out_fluid/dam_break_left'\n",
    "model_file = REPO / 'models/model-10000 .pt'\n",
    "\n",
    "if not model_file.exists():\n",
    "    raise FileNotFoundError(f'モデルが見つかりません: {model_file}')\n",
    "if not (dataset_root / 'valid.npz').exists():\n",
    "    raise FileNotFoundError(f'valid.npz が見つかりません: {dataset_root}')\n",
    "\n",
    "with cfg_src.open('r', encoding='utf-8') as f:\n",
    "    cfg_dict = yaml.safe_load(f)\n",
    "\n",
    "cfg_dict.update({\n",
    "    'mode': 'rollout',\n",
    "    'scenario': 'fluid',\n",
    "    'data_path': str(dataset_root),\n",
    "    'model_path': str(REPO / 'models'),\n",
    "    'model_file': str(model_file),\n",
    "    'rollout_dataset': 'valid',\n",
    "    'rollout_inference_max_examples': None,  # valid 全件\n",
    "    'rollout_max_steps': None,\n",
    "    'train_max_steps_per_trajectory': None,\n",
    "    'valid_max_steps_per_trajectory': None,\n",
    "})\n",
    "fluid_opts = cfg_dict.setdefault('scenario_options', {}).setdefault('fluid', {})\n",
    "fluid_opts['dataset'] = str(dataset_root)\n",
    "fluid_opts['rollout_dataset'] = 'valid'\n",
    "fluid_opts.setdefault('description', 'dam_break_left valid dataset')\n",
    "\n",
    "cfg = Config(**cfg_dict)\n",
    "print('モデル:', model_file)\n",
    "print('データセット:', dataset_root)\n",
    "print('cfg.mode:', cfg.mode, '| rollout_dataset:', cfg.rollout_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf84df64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-step 誤差を時刻ごとに計算\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import data_loader\n",
    "import reading_utils\n",
    "from rollout_utils import rollout\n",
    "from simulator_factory import _get_simulator\n",
    "from train import _prepare_scenario\n",
    "from train_config import INPUT_SEQUENCE_LENGTH\n",
    "from train_paths import _prepare_model_directory, _resolve_model_run_directory, _resolve_model_path\n",
    "from train_utils import _resolve_rollout_dataset_path\n",
    "\n",
    "# 上のセルで組み立てた cfg をそのまま利用\n",
    "cfg = _prepare_scenario(cfg)\n",
    "_prepare_model_directory(cfg)\n",
    "_resolve_model_run_directory(cfg)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "metadata_key = cfg.active_scenario.rollout_metadata_split or 'rollout'\n",
    "metadata = reading_utils.read_metadata(cfg.data_path, metadata_key)\n",
    "\n",
    "simulator = _get_simulator(metadata, cfg.noise_std, cfg.noise_std, device, cfg)\n",
    "model_path = _resolve_model_path(cfg)\n",
    "print('モデルをロード:', model_path)\n",
    "simulator.load(model_path)\n",
    "simulator.to(device)\n",
    "simulator.eval()\n",
    "\n",
    "dataset_path = _resolve_rollout_dataset_path(cfg)\n",
    "print('データセット:', dataset_path)\n",
    "loader = data_loader.get_data_loader_by_trajectories(dataset_path)\n",
    "\n",
    "max_eval_examples = None  # 例: 5 にすると先頭5軌道だけ評価\n",
    "max_steps_cap = None      # 例: 50 にすると 50 ステップまでに制限\n",
    "\n",
    "rmse_time_series = []\n",
    "dt = float(metadata.get('dt', 1.0))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for ex_idx, features in enumerate(loader):\n",
    "        if max_eval_examples is not None and ex_idx >= int(max_eval_examples):\n",
    "            break\n",
    "\n",
    "        positions = features[0].to(device)\n",
    "        particle_type = features[1].to(device)\n",
    "        if len(features) == 4:\n",
    "            material_property = features[2].to(device)\n",
    "            n_particles = torch.tensor([int(features[3])], dtype=torch.int32, device=device)\n",
    "        else:\n",
    "            material_property = None\n",
    "            n_particles = torch.tensor([int(features[2])], dtype=torch.int32, device=device)\n",
    "\n",
    "        nsteps = positions.shape[1] - INPUT_SEQUENCE_LENGTH\n",
    "        if max_steps_cap is not None:\n",
    "            nsteps = min(nsteps, int(max_steps_cap))\n",
    "\n",
    "        _, loss = rollout(\n",
    "            simulator,\n",
    "            positions,\n",
    "            particle_type,\n",
    "            material_property,\n",
    "            n_particles,\n",
    "            nsteps,\n",
    "            device,\n",
    "            show_progress=False,\n",
    "        )\n",
    "\n",
    "        rmse_per_step = torch.sqrt(loss.mean(dim=(1, 2))).cpu().numpy()\n",
    "        time_axis = dt * (INPUT_SEQUENCE_LENGTH + np.arange(1, len(rmse_per_step) + 1))\n",
    "        rmse_time_series.append({\n",
    "            'example': ex_idx,\n",
    "            'time': time_axis,\n",
    "            'rmse': rmse_per_step,\n",
    "        })\n",
    "\n",
    "print(f'評価完了: {len(rmse_time_series)} 件')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9954e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 時刻ごとの RMSE を可視化（各軌道 + 平均）\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if not rmse_time_series:\n",
    "    raise RuntimeError('rmse_time_series が空です。前のセルを確認してください。')\n",
    "\n",
    "max_len = max(len(entry['rmse']) for entry in rmse_time_series)\n",
    "time_grid = np.full((len(rmse_time_series), max_len), np.nan, dtype=float)\n",
    "rmse_grid = np.full_like(time_grid, np.nan)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "for i, entry in enumerate(rmse_time_series):\n",
    "    l = len(entry['rmse'])\n",
    "    time_grid[i, :l] = entry['time']\n",
    "    rmse_grid[i, :l] = entry['rmse']\n",
    "    plt.plot(entry['time'], entry['rmse'], alpha=0.25, label=f\"ex{entry['example']}\")\n",
    "\n",
    "mean_time = np.nanmean(time_grid, axis=0)\n",
    "mean_rmse = np.nanmean(rmse_grid, axis=0)\n",
    "plt.plot(mean_time, mean_rmse, color='red', lw=2, label='mean')\n",
    "\n",
    "plt.xlabel('time [s]')\n",
    "plt.ylabel('position RMSE (1-step)')\n",
    "plt.title('dam_break_left valid: 1-step error vs. time')\n",
    "plt.grid(True)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
