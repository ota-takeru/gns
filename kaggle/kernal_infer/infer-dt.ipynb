{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e989b71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "# Kaggle の入力データセット slug（username/slug の slug 部分）\n",
    "DATASET_SLUG = 'gns-codes'\n",
    "DATASET_ROOT = Path(f'/kaggle/input/{DATASET_SLUG}')\n",
    "WORK_ROOT = Path('/kaggle/working')\n",
    "repo_dir = WORK_ROOT / 'code'\n",
    "\n",
    "code_dir = DATASET_ROOT / 'code'\n",
    "code_zip = DATASET_ROOT / 'code.zip'\n",
    "\n",
    "# 展開済み code/ を優先し、無ければ code.zip を展開\n",
    "if code_dir.exists():\n",
    "    src = code_dir\n",
    "elif code_zip.exists():\n",
    "    if repo_dir.exists():\n",
    "        shutil.rmtree(repo_dir)\n",
    "    with zipfile.ZipFile(code_zip) as zf:\n",
    "        zf.extractall(repo_dir)\n",
    "    src = repo_dir\n",
    "else:\n",
    "    raise FileNotFoundError(f\"/kaggle/input/{DATASET_SLUG} に code も code.zip もありません。Add Data で {DATASET_SLUG} を追加してください。\")\n",
    "\n",
    "# フラット化（zip解凍で1階層挟まった場合）\n",
    "if src != repo_dir:\n",
    "    if repo_dir.exists():\n",
    "        shutil.rmtree(repo_dir)\n",
    "    shutil.copytree(src, repo_dir)\n",
    "if repo_dir.exists():\n",
    "    children = list(repo_dir.iterdir())\n",
    "    if len(children) == 1 and children[0].is_dir():\n",
    "        inner = children[0]\n",
    "        for p in inner.iterdir():\n",
    "            p.rename(repo_dir / p.name)\n",
    "        inner.rmdir()\n",
    "\n",
    "%cd $repo_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf889a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# PyG の radius_graph で必要になる torch-cluster だけインストール\n",
    "import torch\n",
    "\n",
    "torch_ver = torch.__version__.split('+')[0]\n",
    "cuda_ver = torch.version.cuda\n",
    "cuda_tag = 'cpu' if cuda_ver is None else 'cu' + cuda_ver.replace('.', '')\n",
    "url = f\"https://data.pyg.org/whl/torch-{torch_ver}+{cuda_tag}.html\"\n",
    "print('PyG wheels:', url)\n",
    "\n",
    "!pip -q install torch-cluster -f {url}\n",
    "!pip -q install torch_geometric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81493ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import copy\n",
    "import yaml\n",
    "\n",
    "REPO = Path('/kaggle/working/code')\n",
    "cfg_path = REPO / 'config_rollout.yaml'\n",
    "\n",
    "# 推論に使うデータセット（Kaggle Dataset として追加してください）\n",
    "dataset_root = \"/kaggle/input/dam-break-left-800\"\n",
    "\n",
    "# 出力設定\n",
    "output_root = REPO / 'rollouts'\n",
    "viz_format = 'html'  # html|mp4|gif\n",
    "\n",
    "with cfg_path.open('r', encoding='utf-8') as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "# データセットパスとロールアウト設定を上書き\n",
    "cfg['method'] = 'gns'\n",
    "cfg['rollout_inference_max_examples'] = 1\n",
    "cfg['output_path'] = str(output_root)\n",
    "cfg.setdefault('scenario_options', {}).setdefault('fluid', {})['dataset'] = dataset_root\n",
    "\n",
    "# モデルは後続セルで差し替える（ベースを保存しておく）\n",
    "cfg['model_path'] = str(REPO / 'models')\n",
    "cfg['model_file'] = None\n",
    "cfg['output_filename'] = 'rollout'\n",
    "\n",
    "BASE_CFG = copy.deepcopy(cfg)\n",
    "\n",
    "with cfg_path.open('w', encoding='utf-8') as f:\n",
    "    yaml.safe_dump(cfg, f, allow_unicode=True)\n",
    "\n",
    "print('ベース設定を書き出しました:', cfg_path)\n",
    "print('dataset_root:', dataset_root)\n",
    "print('output_path:', cfg['output_path'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0a373b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /kaggle/working/code\n",
    "\n",
    "import copy\n",
    "import re\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "from analyze_rollouts import analyze_rollout\n",
    "\n",
    "# 比較対象モデルを集約（rollout_diff 優先）\n",
    "model_roots = [\n",
    "    REPO / 'models' / 'rollout_diff',\n",
    "    REPO / 'models',\n",
    "]\n",
    "model_files: list[Path] = []\n",
    "for root in model_roots:\n",
    "    if not root.exists():\n",
    "        continue\n",
    "    for path in root.glob('model-*.pt'):\n",
    "        model_files.append(path.resolve())\n",
    "\n",
    "# 重複除去 & ソート（親ディレクトリ優先→ステップ番号）\n",
    "seen = set()\n",
    "unique_models: list[Path] = []\n",
    "for p in model_files:\n",
    "    if p in seen:\n",
    "        continue\n",
    "    seen.add(p)\n",
    "    unique_models.append(p)\n",
    "\n",
    "def _step_key(p: Path):\n",
    "    m = re.search(r'(\\d+)', p.stem)\n",
    "    step = int(m.group(1)) if m else -1\n",
    "    priority = 0 if p.parent.name == 'rollout_diff' else 1\n",
    "    return (priority, p.parent.name, step)\n",
    "\n",
    "model_files = sorted(unique_models, key=_step_key)\n",
    "\n",
    "if not model_files:\n",
    "    raise FileNotFoundError('model-*.pt が見つかりません。models/ 下に配置してください。')\n",
    "\n",
    "print('評価対象モデル:')\n",
    "for p in model_files:\n",
    "    print(' -', p)\n",
    "\n",
    "results = []\n",
    "\n",
    "for model_path in model_files:\n",
    "    tag = f\"{model_path.parent.name}-{model_path.stem}\"\n",
    "    cfg = copy.deepcopy(BASE_CFG)\n",
    "    cfg['model_path'] = str(model_path.parent)\n",
    "    cfg['model_file'] = str(model_path)\n",
    "    cfg['output_filename'] = f\"rollout_{tag}\"\n",
    "\n",
    "    with cfg_path.open('w', encoding='utf-8') as f:\n",
    "        yaml.safe_dump(cfg, f, allow_unicode=True)\n",
    "\n",
    "    cmd = ['python', 'src/train.py', '--config', str(cfg_path)]\n",
    "    print(f\"\\n=== {tag} ===\")\n",
    "    print('Running:', ' '.join(cmd))\n",
    "    subprocess.run(cmd, check=True)\n",
    "\n",
    "    output_dir = Path(cfg['output_path']) / cfg['method'] / cfg['output_filename']\n",
    "    pkl_path = output_dir / f\"{cfg['output_filename']}_ex0.pkl\"\n",
    "    if not pkl_path.exists():\n",
    "        raise FileNotFoundError(f\"{pkl_path} がありません。推論が成功したか確認してください。\")\n",
    "\n",
    "    res = analyze_rollout(pkl_path)\n",
    "    res['tag'] = tag\n",
    "    res['pkl_path'] = str(pkl_path)\n",
    "    results.append(res)\n",
    "    print(f\"  タイムステップ数: {res['n_timesteps']} / 平均距離誤差: {res['mean_distance_error']:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e8e839",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "MAX_SUMMARY_STEPS = 100\n",
    "MAX_PLOT_STEPS = 150  # 1ステップ誤差可視化の表示上限（長すぎると読みにくいため）\n",
    "# モデルごとに評価を打ち切る最大ステップ数を指定（なければ全ステップ）\n",
    "STEP_LIMITS = {\n",
    "    # 'rollout_diff-model-100': 100,\n",
    "    # 'rollout_diff-model-200': 200,\n",
    "}\n",
    "AUTO_LIMIT_FROM_TAG = True  # タグ末尾の数値 (例: model-400) を上限として使う\n",
    "\n",
    "def resolve_limit(tag: str, total_len: int) -> int:\n",
    "    if tag in STEP_LIMITS:\n",
    "        return min(STEP_LIMITS[tag], total_len)\n",
    "    if AUTO_LIMIT_FROM_TAG:\n",
    "        m = re.search(r'(\\d+)(?!.*\\d)', tag)\n",
    "        if m:\n",
    "            return min(int(m.group(1)), total_len)\n",
    "    return total_len\n",
    "\n",
    "if not results:\n",
    "    print('results が空です。前のセルを実行してください。')\n",
    "else:\n",
    "    # -------- 全タイムステップの距離誤差（従来のラインプロット） --------\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for r in results:\n",
    "        err = np.array(r['distance_error_per_timestep'])\n",
    "        limit = resolve_limit(r['tag'], len(err))\n",
    "        err = err[:limit]\n",
    "        timesteps = np.arange(len(err))\n",
    "        plt.plot(\n",
    "            timesteps,\n",
    "            err,\n",
    "            label=f\"{r['tag']} (T={len(err)})\",\n",
    "        )\n",
    "    plt.xlabel('timestep')\n",
    "    plt.ylabel('mean distance error')\n",
    "    plt.title('Rollout distance error per timestep')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plot_path = output_root / 'distance_error_comparison.png'\n",
    "    plt.savefig(plot_path, dpi=150)\n",
    "    plt.show()\n",
    "    print('プロットを保存:', plot_path)\n",
    "\n",
    "    # -------- 1ステップ誤差（タイムステップごと、散布＋線） --------\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for r in results:\n",
    "        err = np.array(r['distance_error_per_timestep'])\n",
    "        limit = resolve_limit(r['tag'], len(err))\n",
    "        limit = min(limit, MAX_PLOT_STEPS)\n",
    "        timesteps = np.arange(limit)\n",
    "        plt.plot(timesteps, err[:limit], marker='o', markersize=3, linewidth=1.2,\n",
    "                 label=f\"{r['tag']} (T={limit})\")\n",
    "    plt.xlabel('timestep')\n",
    "    plt.ylabel('mean distance error (1-step)')\n",
    "    plt.title(f'1-step error per timestep (up to {MAX_PLOT_STEPS} or tag limit)')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plot_path_step = output_root / 'distance_error_per_timestep.png'\n",
    "    plt.savefig(plot_path_step, dpi=150)\n",
    "    plt.show()\n",
    "    print('1ステップ誤差プロットを保存:', plot_path_step)\n",
    "\n",
    "    # -------- サマリ --------\n",
    "    print('\\nサマリ（平均距離誤差と長さ）')\n",
    "    for r in results:\n",
    "        err = np.array(r['distance_error_per_timestep'])\n",
    "        limit = resolve_limit(r['tag'], len(err))\n",
    "        err = err[:limit]\n",
    "        mean_full = float(err.mean())\n",
    "        mean_100 = float(err[:min(MAX_SUMMARY_STEPS, len(err))].mean())\n",
    "        print(f\"- {r['tag']}: steps={len(err)}, mean_full={mean_full:.6f}, mean@<=100={mean_100:.6f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}