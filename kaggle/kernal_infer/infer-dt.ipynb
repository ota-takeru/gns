{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e989b71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "# Kaggle の入力データセット slug（username/slug の slug 部分）\n",
    "DATASET_SLUG = 'gns-codes'\n",
    "DATASET_ROOT = Path(f'/kaggle/input/{DATASET_SLUG}')\n",
    "WORK_ROOT = Path('/kaggle/working')\n",
    "repo_dir = WORK_ROOT / 'code'\n",
    "\n",
    "code_dir = DATASET_ROOT / 'code'\n",
    "code_zip = DATASET_ROOT / 'code.zip'\n",
    "\n",
    "# 展開済み code/ を優先し、無ければ code.zip を展開\n",
    "if code_dir.exists():\n",
    "    src = code_dir\n",
    "elif code_zip.exists():\n",
    "    if repo_dir.exists():\n",
    "        shutil.rmtree(repo_dir)\n",
    "    with zipfile.ZipFile(code_zip) as zf:\n",
    "        zf.extractall(repo_dir)\n",
    "    src = repo_dir\n",
    "else:\n",
    "    raise FileNotFoundError(f\"/kaggle/input/{DATASET_SLUG} に code も code.zip もありません。Add Data で {DATASET_SLUG} を追加してください。\")\n",
    "\n",
    "# フラット化（zip解凍で1階層挟まった場合）\n",
    "if src != repo_dir:\n",
    "    if repo_dir.exists():\n",
    "        shutil.rmtree(repo_dir)\n",
    "    shutil.copytree(src, repo_dir)\n",
    "if repo_dir.exists():\n",
    "    children = list(repo_dir.iterdir())\n",
    "    if len(children) == 1 and children[0].is_dir():\n",
    "        inner = children[0]\n",
    "        for p in inner.iterdir():\n",
    "            p.rename(repo_dir / p.name)\n",
    "        inner.rmdir()\n",
    "\n",
    "%cd $repo_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf889a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# PyG の radius_graph で必要になる torch-cluster だけインストール\n",
    "import torch\n",
    "\n",
    "torch_ver = torch.__version__.split('+')[0]\n",
    "cuda_ver = torch.version.cuda\n",
    "cuda_tag = 'cpu' if cuda_ver is None else 'cu' + cuda_ver.replace('.', '')\n",
    "url = f\"https://data.pyg.org/whl/torch-{torch_ver}+{cuda_tag}.html\"\n",
    "print('PyG wheels:', url)\n",
    "\n",
    "!pip -q install torch-cluster -f {url}\n",
    "!pip -q install torch_geometric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81493ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import yaml\n",
    "\n",
    "%cd /kaggle/working/code\n",
    "\n",
    "import sys\n",
    "sys.path.append(str(Path.cwd() / 'src'))\n",
    "\n",
    "from train_config import Config\n",
    "\n",
    "REPO = Path('/kaggle/working/code')\n",
    "cfg_src = REPO / 'config_rollout.yaml'\n",
    "\n",
    "# 推論に使うデータセット（Kaggle Dataset として追加してください）\n",
    "dataset_root = \"/kaggle/input/dam-break-left\"\n",
    "\n",
    "# 出力設定\n",
    "output_root = REPO / 'rollouts'\n",
    "output_filename = 'inference_result'\n",
    "viz_format = 'html'  # html|mp4|gif\n",
    "\n",
    "with cfg_src.open('r', encoding='utf-8') as f:\n",
    "    cfg_dict = yaml.safe_load(f)\n",
    "\n",
    "cfg_dict['method'] = 'gns'\n",
    "cfg_dict['rollout_inference_max_examples'] = 1\n",
    "cfg_dict.setdefault('scenario_options', {}).setdefault('fluid', {})['dataset'] = dataset_root\n",
    "\n",
    "# モデルはコードに同梱された models/ から取得\n",
    "model_dir = REPO / 'models'\n",
    "cfg_dict['model_path'] = str(model_dir)\n",
    "\n",
    "resolved_model_file = None\n",
    "if model_dir.exists():\n",
    "    expr = re.compile(r'model-(\\d+)\\.pt$')\n",
    "    best = None\n",
    "    for path in model_dir.rglob('model-*.pt'):\n",
    "        m = expr.search(path.name)\n",
    "        step = int(m.group(1)) if m else -1\n",
    "        entry = (path.stat().st_mtime, step, path)\n",
    "        if best is None or entry > best:\n",
    "            best = entry\n",
    "    if best:\n",
    "        resolved_model_file = best[2]\n",
    "\n",
    "if resolved_model_file is not None:\n",
    "    cfg_dict['model_file'] = str(resolved_model_file)\n",
    "else:\n",
    "    cfg_dict['model_file'] = 'latest'  # models/latest を想定\n",
    "\n",
    "cfg_dict['output_path'] = str(output_root)\n",
    "cfg_dict['output_filename'] = output_filename\n",
    "\n",
    "cfg = Config(**cfg_dict)\n",
    "print('model_file:', cfg.model_file)\n",
    "print('output_path:', cfg.output_path)\n",
    "print('output_filename:', cfg.output_filename)\n",
    "print('dataset:', dataset_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0a373b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "# from pathlib import Path\n",
    "# import torch\n",
    "\n",
    "# from predictor import predict\n",
    "# from train import _prepare_scenario\n",
    "# from train_paths import _prepare_model_directory, _resolve_model_run_directory\n",
    "\n",
    "# # 上のセルで用意した cfg をそのまま使用\n",
    "# cfg.rank = 0\n",
    "# cfg.world_size = 1\n",
    "# cfg.local_rank = 0\n",
    "# cfg.enable_ddp = False\n",
    "# cfg = _prepare_scenario(cfg)\n",
    "# _prepare_model_directory(cfg)\n",
    "# _resolve_model_run_directory(cfg)\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# print(f'device: {device}')\n",
    "\n",
    "# predict(cfg, device)\n",
    "\n",
    "# # 可視化\n",
    "# output_dir = Path(cfg.output_path) / cfg.method / cfg.output_filename\n",
    "# pkl_path = output_dir / f\"{cfg.output_filename}_ex0.pkl\"\n",
    "# viz_out = output_dir / f\"{cfg.output_filename}.{viz_format}\"\n",
    "\n",
    "# viz_cmd = [\n",
    "#     'python',\n",
    "#     'visualize_rollout.py',\n",
    "#     str(pkl_path),\n",
    "#     '--format', viz_format,\n",
    "#     '--output', str(viz_out),\n",
    "# ]\n",
    "# print(f\"Visualizing: {' '.join(viz_cmd)}\")\n",
    "# subprocess.run(viz_cmd, check=True)\n",
    "\n",
    "# print(f\"\\n✅ Complete! Output: {viz_out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4057954f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-step 誤差を時間ステップごとに計算（tank_sloshing で評価）\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import data_loader\n",
    "import reading_utils\n",
    "from rollout_utils import rollout\n",
    "from simulator_factory import _get_simulator\n",
    "from train import _prepare_scenario\n",
    "from train_config import INPUT_SEQUENCE_LENGTH\n",
    "from train_paths import _prepare_model_directory, _resolve_model_run_directory, _resolve_model_path\n",
    "from train_utils import _resolve_rollout_dataset_path\n",
    "\n",
    "# cfg をそのまま再利用（未準備なら準備）\n",
    "if getattr(cfg, 'active_scenario', None) is None:\n",
    "    cfg = _prepare_scenario(cfg)\n",
    "_prepare_model_directory(cfg)\n",
    "_resolve_model_run_directory(cfg)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "metadata_key = cfg.active_scenario.rollout_metadata_split or 'rollout'\n",
    "metadata = reading_utils.read_metadata(cfg.data_path, metadata_key)\n",
    "\n",
    "simulator = _get_simulator(metadata, cfg.noise_std, cfg.noise_std, device, cfg)\n",
    "model_path = _resolve_model_path(cfg)\n",
    "print('モデルをロード:', model_path)\n",
    "simulator.load(model_path)\n",
    "simulator.to(device)\n",
    "simulator.eval()\n",
    "\n",
    "dataset_path = _resolve_rollout_dataset_path(cfg)\n",
    "print('データセット:', dataset_path)\n",
    "loader = data_loader.get_data_loader_by_trajectories(dataset_path)\n",
    "\n",
    "max_eval_examples = None  # None で全軌道を評価\n",
    "max_steps_cap = None      # 例: 50 なら 50 ステップまでに制限\n",
    "\n",
    "rmse_time_series = []\n",
    "dt = float(metadata.get('dt', 1.0))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for ex_idx, features in enumerate(loader):\n",
    "        if max_eval_examples is not None and ex_idx >= int(max_eval_examples):\n",
    "            break\n",
    "\n",
    "        positions = features[0].to(device)\n",
    "        particle_type = features[1].to(device)\n",
    "        if len(features) == 4:\n",
    "            material_property = features[2].to(device)\n",
    "            n_particles = torch.tensor([int(features[3])], dtype=torch.int32, device=device)\n",
    "        else:\n",
    "            material_property = None\n",
    "            n_particles = torch.tensor([int(features[2])], dtype=torch.int32, device=device)\n",
    "\n",
    "        nsteps = positions.shape[1] - INPUT_SEQUENCE_LENGTH\n",
    "        if max_steps_cap is not None:\n",
    "            nsteps = min(nsteps, int(max_steps_cap))\n",
    "\n",
    "        _, loss = rollout(\n",
    "            simulator,\n",
    "            positions,\n",
    "            particle_type,\n",
    "            material_property,\n",
    "            n_particles,\n",
    "            nsteps,\n",
    "            device,\n",
    "            show_progress=False,\n",
    "        )\n",
    "\n",
    "        rmse_per_step = torch.sqrt(loss.mean(dim=(1, 2))).cpu().numpy()\n",
    "        frame_axis = INPUT_SEQUENCE_LENGTH + np.arange(1, len(rmse_per_step) + 1)\n",
    "        time_axis = dt * frame_axis\n",
    "        rmse_time_series.append({\n",
    "            'example': ex_idx,\n",
    "            'frame': frame_axis,\n",
    "            'time': time_axis,\n",
    "            'rmse': rmse_per_step,\n",
    "        })\n",
    "\n",
    "print(f'評価完了: {len(rmse_time_series)} 件')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad17b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE の時系列を可視化（各軌道＋平均）\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if not rmse_time_series:\n",
    "    raise RuntimeError('rmse_time_series が空です。前のセルを確認してください。')\n",
    "\n",
    "max_len = max(len(entry['rmse']) for entry in rmse_time_series)\n",
    "frame_grid = np.full((len(rmse_time_series), max_len), np.nan, dtype=float)\n",
    "rmse_grid = np.full_like(frame_grid, np.nan)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "for i, entry in enumerate(rmse_time_series):\n",
    "    l = len(entry['rmse'])\n",
    "    frame_grid[i, :l] = entry['frame']\n",
    "    rmse_grid[i, :l] = entry['rmse']\n",
    "    plt.plot(entry['frame'], entry['rmse'], alpha=0.25, label=f\"ex{entry['example']}\")\n",
    "\n",
    "mean_frame = np.nanmean(frame_grid, axis=0)\n",
    "mean_rmse = np.nanmean(rmse_grid, axis=0)\n",
    "plt.plot(mean_frame, mean_rmse, color='red', lw=2, label='mean')\n",
    "\n",
    "plt.xlabel('frame index')\n",
    "plt.ylabel('position RMSE (1-step)')\n",
    "plt.title('dam-break: 1-step error vs. frame')\n",
    "plt.grid(True)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}