{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "# Kaggle \u306e\u5165\u529b\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8 slug\uff08username/slug \u306e slug \u90e8\u5206\uff09\u3092\u30bb\u30c3\u30c8\n",
    "DATASET_SLUG = 'gns-codes'  # \u5909\u66f4\u3059\u308b\u5834\u5408\u306f\u3053\u3053\u3092\u66f4\u65b0\n",
    "DATASET_ROOT = Path(f'/kaggle/input/{DATASET_SLUG}')\n",
    "WORK_ROOT = Path('/kaggle/working')\n",
    "repo_dir = WORK_ROOT / 'code'\n",
    "\n",
    "code_dir = DATASET_ROOT / 'code'\n",
    "code_zip = DATASET_ROOT / 'code.zip'\n",
    "\n",
    "# \u53d6\u5f97\u512a\u5148\u9806\u4f4d: \u5c55\u958b\u6e08\u307f code/ \u304c\u3042\u308c\u3070\u305d\u308c\u3092\u4f7f\u3046\u3002\u7121\u3051\u308c\u3070 code.zip \u3092\u5c55\u958b\u3002\u3069\u3061\u3089\u3082\u7121\u3051\u308c\u3070\u30a8\u30e9\u30fc\u3002\n",
    "if code_dir.exists():\n",
    "    src = code_dir\n",
    "elif code_zip.exists():\n",
    "    if repo_dir.exists():\n",
    "        shutil.rmtree(repo_dir)\n",
    "    with zipfile.ZipFile(code_zip) as zf:\n",
    "        zf.extractall(repo_dir)\n",
    "    src = repo_dir\n",
    "else:\n",
    "    raise FileNotFoundError(f\"/kaggle/input/{DATASET_SLUG} \u306b code \u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3082 code.zip \u3082\u898b\u3064\u304b\u308a\u307e\u305b\u3093\u3002Add Data \u3067 {DATASET_SLUG} \u3092\u8ffd\u52a0\u3057\u3066\u304f\u3060\u3055\u3044\u3002\")\n",
    "\n",
    "if src != repo_dir:\n",
    "    if repo_dir.exists():\n",
    "        shutil.rmtree(repo_dir)\n",
    "    shutil.copytree(src, repo_dir)\n",
    "# unzip \u3067\u30b5\u30d6\u30c7\u30a3\u30ec\u30af\u30c8\u30ea1\u968e\u5c64\u631f\u307e\u3063\u305f\u5834\u5408\u306b\u5e73\u5766\u5316\n",
    "if repo_dir.exists():\n",
    "    children = list(repo_dir.iterdir())\n",
    "    if len(children)==1 and children[0].is_dir():\n",
    "        inner = children[0]\n",
    "        for path in inner.iterdir():\n",
    "            path.rename(repo_dir / path.name)\n",
    "        inner.rmdir()\n",
    "%cd $repo_dir\n",
    "# \u4f9d\u5b58\u30d1\u30c3\u30b1\u30fc\u30b8\u306f Kaggle \u74b0\u5883\u306e\u6a19\u6e96\u30e9\u30a4\u30d6\u30e9\u30ea\u3092\u5229\u7528\uff08\u8ffd\u52a0\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u306a\u3057\uff09\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install torch-geometric \n",
    "# torch-scatter torch-sparse torch-cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch_ver = torch.__version__.split(\"+\")[0]          # \u4f8b: \"2.1.0+cu121\" -> \"2.1.0\"\n",
    "cuda_ver  = torch.version.cuda                      # \u4f8b: \"12.1\" / CPU\u306a\u3089 None\n",
    "cuda_tag  = \"cpu\" if cuda_ver is None else \"cu\" + cuda_ver.replace(\".\", \"\")\n",
    "\n",
    "url = f\"https://data.pyg.org/whl/torch-{torch_ver}+{cuda_tag}.html\"\n",
    "print(\"PyG wheels:\", url)\n",
    "\n",
    "# \u5fc5\u8981\u306a\u3084\u3064\u3060\u3051\u5165\u308c\u308b\uff08radius_graph\u306a\u3089 torch_cluster \u304c\u672c\u4f53\uff09\n",
    "!pip -q install torch-cluster -f {url}\n",
    "\n",
    "# \u3082\u3057\u4ed6\u3082\u4f7f\u3046\u306a\u3089\u307e\u3068\u3081\u3066\n",
    "# !pip -q install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f {url}\n",
    "# !pip -q install torch_geometric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d052534c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "import re\n",
    "import yaml\n",
    "\n",
    "REPO = Path('/kaggle/working/code')\n",
    "cfg_path = REPO / 'config_rollout.yaml'\n",
    "\n",
    "# \u63a8\u8ad6\u3067\u4f7f\u3046\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\n",
    "dataset_root = '/kaggle/input/dam-break-left'\n",
    "\n",
    "# \u8a66\u3057\u305f\u3044 dt \u3092\u5217\u6319\n",
    "DT_LIST = [0.006, 0.003]  # \u3053\u3053\u3092\u7de8\u96c6\n",
    "\n",
    "# \u51fa\u529b\u5148\n",
    "output_root = REPO / 'rollouts_dt'\n",
    "\n",
    "# \u8ffd\u52a0\u3067\u30e2\u30c7\u30eb\u3092\u7f6e\u3044\u305f Kaggle Dataset\n",
    "# \u4f8b: /kaggle/input/gns-40k-100-20/pytorch/default/1\n",
    "MODEL_DATASET_SLUG = 'gns-40k-100-20'\n",
    "MODEL_SUBDIR = 'pytorch/default/1'\n",
    "# \u30e2\u30c7\u30eb\u30d5\u30a1\u30a4\u30eb\u540d (model-*.pt \u3092\u81ea\u52d5\u63a2\u7d22\u3059\u308b\u306a\u3089 latest \u306e\u307e\u307e)\n",
    "MODEL_FILE = 'latest'\n",
    "\n",
    "with cfg_path.open('r', encoding='utf-8') as f:\n",
    "    base_cfg = yaml.safe_load(f)\n",
    "\n",
    "base_cfg['method'] = 'gns'\n",
    "base_cfg['rollout_inference_max_examples'] = 1\n",
    "base_cfg.setdefault('scenario_options', {}).setdefault('fluid', {})['dataset'] = dataset_root\n",
    "\n",
    "# used_config.json \u3092\u66f8\u304f\u306e\u3067 model_path \u306f\u66f8\u304d\u8fbc\u307f\u53ef\u80fd\u306a\u5834\u6240\u306b\u56fa\u5b9a\n",
    "base_cfg['model_path'] = str(REPO / 'models')\n",
    "\n",
    "# \u65e2\u306b\u30e2\u30c7\u30eb\u304c\u7f6e\u304b\u308c\u3066\u3044\u308b\u5834\u6240\u304c\u3042\u308c\u3070\u81ea\u52d5\u3067\u4f7f\u3046\n",
    "model_candidates = []\n",
    "if MODEL_DATASET_SLUG:\n",
    "    dataset_root_path = Path(f'/kaggle/input/{MODEL_DATASET_SLUG}')\n",
    "    model_candidates.append(dataset_root_path / MODEL_SUBDIR if MODEL_SUBDIR else dataset_root_path)\n",
    "model_candidates.extend([\n",
    "    Path('/kaggle/input/gns-codes') / 'models',\n",
    "])\n",
    "\n",
    "selected_model = None\n",
    "resolved_model_file = None\n",
    "for candidate in model_candidates:\n",
    "    if not candidate.exists():\n",
    "        continue\n",
    "    if candidate.is_file():\n",
    "        resolved_model_file = candidate\n",
    "    else:\n",
    "        if MODEL_FILE == 'latest':\n",
    "            expr = re.compile(r\"model-(\\d+)\\.pt$\")\n",
    "            best = None\n",
    "            for path in candidate.rglob('model-*.pt'):\n",
    "                m = expr.search(path.name)\n",
    "                step = int(m.group(1)) if m else -1\n",
    "                stat = path.stat()\n",
    "                entry = (stat.st_mtime, step, path)\n",
    "                if best is None or entry > best:\n",
    "                    best = entry\n",
    "            if best:\n",
    "                resolved_model_file = best[2]\n",
    "        else:\n",
    "            resolved_model_file = candidate / MODEL_FILE\n",
    "    selected_model = candidate\n",
    "    if resolved_model_file is not None:\n",
    "        break\n",
    "\n",
    "if resolved_model_file is not None:\n",
    "    base_cfg['model_file'] = str(resolved_model_file)\n",
    "\n",
    "print(f\"model candidates: {[str(p) for p in model_candidates]}\")\n",
    "print(f\"selected model path: {selected_model}\")\n",
    "print(f\"resolved model file: {resolved_model_file}\")\n",
    "\n",
    "\n",
    "def _dt_label(value: float) -> str:\n",
    "    return str(value).replace('.', 'p')\n",
    "\n",
    "cfg_variants = []\n",
    "for dt in DT_LIST:\n",
    "    cfg_dt = deepcopy(base_cfg)\n",
    "    method_opts = cfg_dt.setdefault('method_options', {}).setdefault('hamiltonian_sph', {})\n",
    "    integrator = method_opts.setdefault('integrator', {})\n",
    "    integrator['dt'] = float(dt)\n",
    "    integrator['dt_source'] = 'config'\n",
    "    label = _dt_label(float(dt))\n",
    "    cfg_dt['output_path'] = str(output_root / f\"dt_{label}\")\n",
    "    cfg_dt['output_filename'] = f\"rollout_dt_{label}\"\n",
    "    cfg_variants.append((label, cfg_dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%cd /kaggle/working/code\n",
    "\n",
    "import subprocess\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "cfg_path = Path('config_rollout.yaml')\n",
    "for label, cfg_dt in cfg_variants:\n",
    "    with cfg_path.open('w', encoding='utf-8') as f:\n",
    "        yaml.safe_dump(cfg_dt, f, allow_unicode=True)\n",
    "    cmd = [\"python\", \"src/train.py\", \"--config\", \"config_rollout.yaml\"]\n",
    "    print(f\"[dt={label}] {' '.join(cmd)}\")\n",
    "    subprocess.run(cmd, check=True)\n",
    "    subprocess.run([\"python\", \"analyze_rollouts.py\", \"--rollouts-dir\", cfg_dt['output_path']], check=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af7fc0e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!ls -la /kaggle/input/gns-40k-100-20\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}