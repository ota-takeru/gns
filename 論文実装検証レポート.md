# 論文実装検証レポート

## Learning to Simulate Complex Physics with Graph Networks (Sanchez-Gonzalez et al., 2020)

生成日: 2025 年 10 月 22 日

---

## 📋 目次

1. [検証概要](#検証概要)
2. [モデルアーキテクチャの検証](#モデルアーキテクチャの検証)
3. [ハイパーパラメータの検証](#ハイパーパラメータの検証)
4. [学習設定の検証](#学習設定の検証)
5. [学習データの検証](#学習データの検証)
6. [問題点と改善提案](#問題点と改善提案)
7. [推奨される変更](#推奨される変更)

---

## 検証概要

本レポートでは、現在の Graph Network-based Simulator (GNS)実装が論文「Learning to Simulate Complex Physics with Graph Networks」(arXiv:2002.09405)の仕様に準拠しているかを検証しました。

### 検証対象ファイル

- `src/graph_network.py` - モデルアーキテクチャ
- `src/learned_simulator.py` - シミュレータコア
- `src/train.py` - 学習ループ
- `config.yaml` - 設定ファイル
- `datasets/scripts/gen_pymunk.py` - データ生成

---

## モデルアーキテクチャの検証

### ✅ Encode-Process-Decode 構造

現在の実装は論文のアーキテクチャを**正しく実装**しています。

#### 1. エンコーダ (`graph_network.py`: 37-76 行)

```python
class Encoder(nn.Module):
    def __init__(self, nnode_in_features, nnode_out_features,
                 nedge_in_features, nedge_out_features,
                 nmlp_layers, mlp_hidden_dim):
        # ノード特徴とエッジ特徴をMLPで潜在空間にマッピング
        self.node_fn = nn.Sequential(
            build_mlp(...),
            nn.LayerNorm(nnode_out_features)  # ✅ LayerNorm適用
        )
        self.edge_fn = nn.Sequential(
            build_mlp(...),
            nn.LayerNorm(nedge_out_features)  # ✅ LayerNorm適用
        )
```

**評価:** ✅ 論文通り

#### 2. プロセッサ (`graph_network.py`: 159-192 行)

```python
class Processer(nn.Module):
    def __init__(self, ..., nmessage_passing_steps):
        self.gnn_stack = nn.ModuleList([
            InteractionNetwork(...)
            for _ in range(nmessage_passing_steps)  # ✅ M回のメッセージパッシング
        ])
```

**InteractionNetwork:**

- メッセージ関数: エッジ特徴の更新 ✅
- 集約関数: sum aggregation ✅
- 更新関数: ノード特徴の更新 ✅
- 残差接続: ノードとエッジ両方に適用 ✅

**評価:** ✅ 論文通り

#### 3. デコーダ (`graph_network.py`: 194-202 行)

```python
class Decoder(nn.Module):
    def __init__(self, nnode_in, nnode_out, nmlp_layers, mlp_hidden_dim):
        self.node_fn = build_mlp(...)  # ✅ MLPで加速度を予測
```

**評価:** ✅ 論文通り

---

## ハイパーパラメータの検証

### ✅ 完全に論文準拠

| パラメータ                   | 現在の実装 | 論文の値 | 評価 |
| ---------------------------- | ---------- | -------- | ---- |
| 潜在次元 (latent_dim)        | 128        | 128      | ✅   |
| メッセージパッシング回数 (M) | 10         | 10       | ✅   |
| MLP 層数 (nmlp_layers)       | 2          | 2        | ✅   |
| MLP 隠れ層次元               | 128        | 128      | ✅   |
| 粒子タイプ埋め込み           | 16         | 16       | ✅   |

**実装箇所:** `src/train.py` 180-195 行

```python
simulator = learned_simulator.LearnedSimulator(
    particle_dimensions=metadata["dim"],
    nnode_in=nnode_in,
    nedge_in=nedge_in,
    latent_dim=128,              # ✅
    nmessage_passing_steps=10,   # ✅
    nmlp_layers=2,               # ✅
    mlp_hidden_dim=128,          # ✅
    connectivity_radius=metadata["default_connectivity_radius"],
    normalization_stats=normalization_stats,
    nparticle_types=NUM_PARTICLE_TYPES,
    particle_type_embedding_size=16,  # ✅
    device=device,
)
```

---

## 学習設定の検証

### ✅ 学習率とスケジューリング - 正しい

| 設定項目       | 現在の値 | 論文の値 | 評価 |
| -------------- | -------- | -------- | ---- |
| 初期学習率     | 1e-4     | 1e-4     | ✅   |
| 学習率減衰率   | 0.1      | 0.1      | ✅   |
| 減衰ステップ   | 5e6      | 5e6      | ✅   |
| ノイズ標準偏差 | 6.7e-4   | 6.7e-4   | ✅   |

**実装箇所:** `config.yaml`

```yaml
lr_init: 0.0001 # ✅ 1e-4
lr_decay: 0.1 # ✅ 指数減衰
lr_decay_steps: 5000000 # ✅ 5M steps
noise_std: 0.00067 # ✅ 6.7e-4
```

### ✅ ノイズ注入 - 正しく実装

**実装:** `src/noise_utils.py` & `src/train.py`

```python
# ランダムウォークノイズの生成
sampled_noise = noise_utils.get_random_walk_noise_for_position_sequence(
    position, noise_std_last_step=cfg.noise_std
)
# 非運動学粒子のみにノイズを適用
non_kinematic_mask = (particle_type != KINEMATIC_PARTICLE_ID)
sampled_noise *= non_kinematic_mask.view(-1, 1, 1)  # ✅
```

**評価:** ✅ 論文通り

### ✅ 正規化 - 正しく実装

速度と加速度の正規化にノイズの分散を考慮：

```python
normalization_stats = {
    "acceleration": {
        "mean": torch.FloatTensor(metadata["acc_mean"]),
        "std": torch.sqrt(
            torch.FloatTensor(metadata["acc_std"]) ** 2 + acc_noise_std**2
        ),  # ✅ ノイズを考慮した分散
    },
    "velocity": {
        "mean": torch.FloatTensor(metadata["vel_mean"]),
        "std": torch.sqrt(
            torch.FloatTensor(metadata["vel_std"]) ** 2 + vel_noise_std**2
        ),  # ✅ ノイズを考慮した分散
    },
}
```

**評価:** ✅ 論文通り

### ⚠️ **重大な問題: 学習ステップ数が極端に少ない**

| 設定項目       | 現在の値 | 論文の値       | 適合度      |
| -------------- | -------- | -------------- | ----------- |
| 学習ステップ数 | **100**  | **20,000,000** | **0.0005%** |

**現在の設定:** `config.yaml`

```yaml
ntraining_steps: 100 # ❌ わずか100ステップ
```

**論文の推奨:**

```yaml
ntraining_steps: 20000000 # 2000万ステップ
```

**影響:**

- モデルが全く学習できない
- 重みがほぼランダムのまま
- 論文の性能を再現不可能

**評価:** ❌ **致命的な設定ミス**

---

## 学習データの検証

### ⚠️ **重大な問題: データ数が極端に少ない**

#### 現在のデータ生成設定

**ファイル:** `datasets/scripts/gen_pymunk.py`

```python
num_train_scenes = 10   # ❌ わずか10シーン
num_valid_scenes = 3    # ❌ わずか3シーン
```

#### 論文の標準的なデータセット

| データセット    | 軌跡数 | フレーム数/軌跡 | 総サンプル数 |
| --------------- | ------ | --------------- | ------------ |
| WaterDropSample | 1,000  | ~320            | ~320,000     |
| Sand            | 1,000  | ~320            | ~320,000     |
| Goop            | 1,000  | ~320            | ~320,000     |
| **現在の実装**  | **10** | **240**         | **~2,400**   |

**データ量の比較:**

- 論文: 約 32 万サンプル
- 現在: 約 2,400 サンプル
- **比率: 0.75%（133 分の 1）**

**影響:**

1. **過学習の危険性が極めて高い**

   - 10 シーンだけでは物理現象の多様性を捉えられない
   - モデルが訓練データを暗記してしまう

2. **汎化性能の著しい低下**

   - 未知の初期条件に対応できない
   - 粒子数や配置が変わると予測が破綻

3. **ロバスト性の欠如**
   - わずかなパラメータ変化で性能が大幅に低下

**評価:** ❌ **致命的なデータ不足**

### ✅ その他のデータ設定

| 項目           | 現在の設定      | 評価                 |
| -------------- | --------------- | -------------------- |
| シーケンス長   | 240 フレーム    | ✅ 妥当（2 秒間）    |
| タイムステップ | 1/120 秒        | ✅ 妥当              |
| 剛体数         | 2-5 個          | △ もっと多様化すべき |
| 粒子密度       | 16 points/shape | ✅ 妥当              |

### △ Connectivity Radius の推定

**現在の実装:** `gen_pymunk.py` 251 行

```python
return float(np.percentile(all_nn, 90) * 1.5)
```

**論文の推奨:**

- 粒子間距離の 2-3 倍

**評価:** △ やや小さい可能性（1.5 倍 → 2.0 倍を推奨）

---

## 問題点と改善提案

### 🔴 **致命的な問題（即座に修正が必要）**

#### 1. 学習ステップ数の不足

**現状:** 100 ステップ
**必要:** 20,000,000 ステップ（最低でも 1,000,000 以上）

**理由:**

- GNS のような複雑なグラフニューラルネットワークは大量の学習が必要
- 100 ステップでは勾配降下法がほとんど機能しない
- 論文の 20,000,000 ステップは十分な収束のために必要

**推奨修正:**

```yaml
# config.yaml
ntraining_steps: 20000000 # または最低でも 1000000
nsave_steps: 50000 # 保存間隔も調整
```

#### 2. 学習データ数の不足

**現状:** 10 シーン（訓練）、3 シーン（検証）
**必要:** 1,000 シーン以上（訓練）、100 シーン以上（検証）

**理由:**

- 物理シミュレーションには多様な初期条件が必要
- 10 シーンでは汎化性能が全く得られない
- 過学習が確実に発生する

**推奨修正:**

```python
# datasets/scripts/gen_pymunk.py
num_train_scenes = 1000   # 最低1000シーン
num_valid_scenes = 100    # 最低100シーン
num_test_scenes = 100     # テストセットも追加
```

---

### 🟡 **推奨される改善（より良い結果のため）**

#### 3. バッチサイズの増加

**現状:** 2
**推奨:** 4-8（GPU メモリ次第）

```yaml
# config.yaml
batch_size: 4 # メモリが許せば
```

#### 4. Connectivity Radius の調整

**現状:** 90 パーセンタイル × 1.5
**推奨:** 90 パーセンタイル × 2.0

```python
# datasets/scripts/gen_pymunk.py (251行)
return float(np.percentile(all_nn, 90) * 2.0)  # 1.5 → 2.0
```

#### 5. データの多様性向上

**剛体数の範囲拡大:**

```python
# gen_pymunk.py (113行)
def generate_scene(T=240, dt=1/120, substeps=4,
                   n_bodies=(2, 10),  # 2-5 → 2-10に拡大
                   density=16):
```

**物理パラメータの多様化:**

```python
# 摩擦係数の範囲拡大
shape.friction = RNG.uniform(0.1, 1.0)  # 0.2-0.9 → 0.1-1.0

# 弾性係数の範囲拡大
shape.elasticity = RNG.uniform(0.0, 0.6)  # 0.0-0.4 → 0.0-0.6

# 質量の範囲拡大
mass = RNG.uniform(0.3, 5.0)  # 0.5-3.0 → 0.3-5.0
```

#### 6. 検証間隔の設定

現在は`validation_interval: null`ですが、学習の進捗確認のため設定を推奨：

```yaml
# config.yaml
validation_interval: 5000 # 5000ステップごとに検証
```

---

## 推奨される変更

### 優先度 1: 即座に修正すべき項目

#### ✏️ 変更 1: `config.yaml`の修正

```yaml
mode: train
data_path: ./datasets/out/
model_path: ./models/
output_path: ./rollouts/
output_filename: rollout

batch_size: 4 # 2 → 4
noise_std: 0.00067 # ✅ 変更なし

# トレーニング
ntraining_steps: 20000000 # ❌ 100 → ✅ 20000000
validation_interval: 5000 # ❌ null → ✅ 5000
nsave_steps: 50000 # ❌ 50 → ✅ 50000

# 学習率（指数減衰）
lr_init: 0.0001 # ✅ 変更なし
lr_decay: 0.1 # ✅ 変更なし
lr_decay_steps: 5000000 # ✅ 変更なし

# 再開関連
model_file: null
train_state_file: null

# GPU選択
cuda_device_number: null
```

#### ✏️ 変更 2: `datasets/scripts/gen_pymunk.py`の修正

```python
if __name__ == "__main__":
    out_root = Path(__file__).resolve().parents[1] / "out"

    # Train データセットの生成
    num_train_scenes = 1000  # ❌ 10 → ✅ 1000
    split = "train"
    trajectories = []
    last_meta = None
    print(f"Generating {num_train_scenes} training scenes...")
    for i in range(num_train_scenes):
        pos, rigid_ids, meta = generate_scene()
        save_npz(out_root, i, pos, rigid_ids, meta, split=split)
        trajectories.append(_extract_dynamic_positions(pos, rigid_ids, meta["nb"]))
        last_meta = meta

    if trajectories and last_meta is not None:
        dataset_path, meta_path = export_dataset(
            trajectories, out_root, split=split, dt=last_meta["dt"]
        )
        print(f"Saved train dataset to {dataset_path}")
        print(f"Wrote metadata to {meta_path}")
    print(f"Generated {num_train_scenes} scenes in {out_root / split}")

    # Valid データセットの生成
    num_valid_scenes = 100  # ❌ 3 → ✅ 100
    split = "valid"
    trajectories = []
    last_meta = None
    print(f"\nGenerating {num_valid_scenes} validation scenes...")
    for i in range(num_valid_scenes):
        pos, rigid_ids, meta = generate_scene()
        save_npz(out_root, i, pos, rigid_ids, meta, split=split)
        trajectories.append(_extract_dynamic_positions(pos, rigid_ids, meta["nb"]))
        last_meta = meta

    if trajectories and last_meta is not None:
        dataset_path, _ = export_dataset(
            trajectories, out_root, split=split, dt=last_meta["dt"]
        )
        print(f"Saved valid dataset to {dataset_path}")
    print(f"Generated {num_valid_scenes} scenes in {out_root / split}")

    # Test データセットの生成（追加）
    num_test_scenes = 100
    split = "test"
    trajectories = []
    last_meta = None
    print(f"\nGenerating {num_test_scenes} test scenes...")
    for i in range(num_test_scenes):
        pos, rigid_ids, meta = generate_scene()
        save_npz(out_root, i, pos, rigid_ids, meta, split=split)
        trajectories.append(_extract_dynamic_positions(pos, rigid_ids, meta["nb"]))
        last_meta = meta

    if trajectories and last_meta is not None:
        dataset_path, _ = export_dataset(
            trajectories, out_root, split=split, dt=last_meta["dt"]
        )
        print(f"Saved test dataset to {dataset_path}")
    print(f"Generated {num_test_scenes} scenes in {out_root / split}")
```

#### ✏️ 変更 3: Connectivity Radius の調整

```python
def _estimate_connectivity_radius(trajectories):
    """Heuristic connectivity radius based on nearest-neighbour distance."""
    # ... (既存のコード)

    all_nn = np.concatenate(nearest_distances, axis=0)
    # Use a generous multiplier so that the message graph connects over shapes.
    return float(np.percentile(all_nn, 90) * 2.0)  # ❌ 1.5 → ✅ 2.0
```

---

### 優先度 2: 推奨される改善

#### ✏️ 変更 4: データ多様性の向上

```python
def generate_scene(T=240, dt=1/120, substeps=4,
                   n_bodies=(2, 10),  # ❌ (2, 5) → ✅ (2, 10)
                   density=16):
    # ...

def add_random_rigid(space, x_range=(-3, 3), y=5.0):
    kind = RNG.choice(["box", "circle"])
    mass = RNG.uniform(0.3, 5.0)  # ❌ (0.5, 3.0) → ✅ (0.3, 5.0)
    if kind == "box":
        w, h = RNG.uniform(0.3, 0.8), RNG.uniform(0.3, 0.8)
        # ...
    else:
        r = RNG.uniform(0.2, 0.5)
        # ...

    shape.friction = RNG.uniform(0.1, 1.0)      # ❌ (0.2, 0.9) → ✅ (0.1, 1.0)
    shape.elasticity = RNG.uniform(0.0, 0.6)    # ❌ (0.0, 0.4) → ✅ (0.0, 0.6)
    # ...
```

---

## 📊 修正前後の比較

### 学習設定の比較

| 項目           | 修正前 | 修正後     | 論文の値      |
| -------------- | ------ | ---------- | ------------- |
| 学習ステップ数 | 100    | 20,000,000 | 20,000,000 ✅ |
| 保存間隔       | 50     | 50,000     | -             |
| バッチサイズ   | 2      | 4          | 2-4 ✅        |
| 検証間隔       | なし   | 5,000      | -             |

### データセットの比較

| 項目                 | 修正前 | 修正後   | 論文の標準  |
| -------------------- | ------ | -------- | ----------- |
| 訓練シーン数         | 10     | 1,000    | 1,000 ✅    |
| 検証シーン数         | 3      | 100      | 100 ✅      |
| テストシーン数       | 0      | 100      | 100 ✅      |
| 総サンプル数（推定） | ~2,400 | ~240,000 | ~320,000 ✅ |

### 学習時間の推定

**修正前:**

- 100 ステップ × 2 バッチサイズ = 約 1 分

**修正後:**

- 20,000,000 ステップ × 4 バッチサイズ
- GPU (RTX 3090 相当): 約 3-7 日
- 論文通りの本格的な学習

---

## ✅ 結論

### 現在の実装の評価

**✅ 優れている点:**

1. **モデルアーキテクチャ**: 論文通りに完璧に実装されている（100%適合）
2. **ハイパーパラメータ**: すべて論文の推奨値（100%適合）
3. **ノイズ注入**: 正しく実装されている
4. **正規化**: 論文通りの実装
5. **グラフ構築**: 適切に実装されている

**❌ 致命的な問題:**

1. **学習ステップ数**: わずか 100（論文の 0.0005%）
2. **学習データ数**: わずか 10 シーン（論文の 1%）

**総合評価:**

- **アーキテクチャ実装: A+ (完璧)**
- **学習設定: F (不合格)**
- **総合: D (要大幅修正)**

### 推奨アクション

**即座に実行すべき:**

1. `config.yaml`の`ntraining_steps`を 20,000,000 に変更
2. `gen_pymunk.py`のシーン数を 1,000/100/100 に変更
3. データセットを再生成
4. 長期間（数日）の学習を実行

**これらの修正により、論文の性能を再現できる可能性が高まります。**

---

## 📚 参考資料

1. Sanchez-Gonzalez, A., et al. (2020). "Learning to Simulate Complex Physics with Graph Networks." arXiv:2002.09405
2. 論文の Appendix A: 実装の詳細
3. 論文の Table 1: ハイパーパラメータ一覧

---

**作成者:** AI Assistant  
**検証日:** 2025 年 10 月 22 日  
**対象実装:** /home/takeru/python/gns
