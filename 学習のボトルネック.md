以下を確認して、学習時のボトルネック候補と高速化策を洗い出しました。実装箇所の参照も併記します。

【主なボトルネック】

グラフ構築とGNN計算
近傍グラフ構築: radius_graph 呼び出しと batch_ids 生成が毎ステップ発生
learned_simulator: src/learned_simulator.py:45（_compute_graph_connectivity）
メッセージパッシングと多数のMLP + LayerNorm
graph_network: src/graph_network.py:83（InteractionNetwork）～全体
データ転送と前処理
DataLoader は pin_memory=True だが num_workers 未指定（デフォルト0）
data_loader: src/data_loader.py:218
.to(device) が全テンソルに都度発生し、non_blocking未使用
train loop: src/train.py:517, src/train.py:518, src/train.py:520 など
ノイズ生成のデバイス不整合とコピー
ノイズがCPUで生成→GPUへ転送（かつGPU入力との混在でエラー/転送増の可能性）
noise_utils: src/noise_utils.py:8（get_random_walk_noise_for_position_sequence）
【改善ポイントと推定効果】

混合精度（AMP）とTF32の有効化

内容: CUDA環境で torch.cuda.amp.autocast + GradScaler を学習時の forward/backward に適用。Ampere以降は torch.set_float32_matmul_precision("high") でTF32もON。
変更点: trainの forward/loss/backward を autocast で囲み、optimizer.stepに scaler を使う。初期化部で matmul precision を設定。
効果目安: 1.3〜2.0x（GPU・モデル次第。GNSはMLP主体なので効きやすい）
参照: src/train.py（学習ループ周辺）, main() 付近で TF32 有効化
DataLoader の並列化と前取り

内容: num_workers>0, persistent_workers=True, prefetch_factor=2〜4 を指定。CPU前処理を非同期化。
変更点: get_data_loader_by_samples 呼び出し側（src/train.py:487 付近）または関数定義（src/data_loader.py:218）で引数を増やす。
効果目安: 1.1〜1.5x（CPU前処理がボトルネックの場合）
H2D 転送の非同期化

内容: .to(device, non_blocking=True) を適用（pin_memory=True とセットで効果）。
変更点: src/train.py:517,518,520,521,524,527 など .to(device) 箇所。
効果目安: 5〜15%（転送待ちが目立つ環境）
ノイズ生成を入力テンソルと同じデバイスで

内容: noise_utils.get_random_walk_noise_for_position_sequence 内の torch.randn を device=position_sequence.device で生成。zeros_like も同デバイス。
変更点: src/noise_utils.py:8 の関数内。CPU→GPUコピー削減と混在の潜在バグ解消。
効果目安: 2〜10%（GPU利用時のコピー削減＋安定化）
batch_ids の高速生成（Pythonループ排除）

内容: _compute_graph_connectivity 内で torch.cat([...]) ではなく repeat_interleave を使ってデバイス上で一発生成。
例: batch_ids = torch.repeat_interleave(torch.arange(B, device=node_position.device), nparticles_per_example.to(torch.long))
変更点: src/learned_simulator.py:45 直下の batch_ids = ...（src/learned_simulator.py:54）
効果目安: 5〜20%（粒子数が多いほど効く、半径グラフ作成の一部を短縮）
radius_graph のGPU実行を確実化

内容: 入力テンソル（node_position, batch_ids）をGPU上に。torch-cluster がCUDA対応ビルドであることを確認。
変更点: _compute_graph_connectivity 内の to(self._device) を node_position.device に合わせるなど整合性を強化。
効果目安: 大（CPUで半径グラフを回していた場合は桁違いに速い）
torch.compile の活用（PyTorch 2.x）

内容: EncodeProcessDecode 全体を torch.compile 包装でkernel融合最適化。
効果目安: 1.1〜1.3x（環境とGPUによる）
GNN計算量の削減（精度/安定性とトレードオフ）

nmessage_passing_steps=10 を 5〜8 に短縮 → 計算ほぼ線形に減少（例: 10→5でGNN部2x）
latent_dim=128 を 96/64 に縮小 → MLP/LNのモデル計算減
connectivity_radius を小さく設定して平均エッジ数Eを削減 → メッセージパッシングは O(E)
効果目安: 20〜50%以上（ただし精度影響あり。妥当な範囲で）
保存頻度見直し

内容: nsave_steps=5000 は妥当だがI/Oが遅い環境では一時的に止まるので、I/Oが顕著な場合は頻度を下げるか非同期化を検討。
効果目安: 数％〜スパイク回避
【具体的な変更提案（最小差分）】

非同期転送

src/train.py:517 など
例: position = example[0][0].to(device, non_blocking=True)
particle_type, material_property, n_particles_per_example, labels も同様
DataLoader 並列化

src/data_loader.py:218 を拡張:
def get_data_loader_by_samples(..., num_workers=4, persistent_workers=True, prefetch_factor=2):
DataLoader(..., num_workers=num_workers, persistent_workers=persistent_workers, prefetch_factor=prefetch_factor, ...)
呼び出し側 src/train.py:487 に引数を渡す
ノイズのデバイス合わせ

src/noise_utils.py:8 内で
device = position_sequence.device
velocity_sequence_noise = torch.randn(velocity_sequence.shape, device=device) * (...)
position_sequence_noise = torch.zeros_like(position_sequence, device=device)
外側の .to(device) は不要になる（削除または残しても実害なし）
batch_ids の repeat_interleave 化

src/learned_simulator.py:54 付近を
B = int(nparticles_per_example.numel())
batch_ids = torch.repeat_interleave(torch.arange(B, device=node_position.device), nparticles_per_example.to(torch.long))
AMP/TF32

src/train.py 学習ループで
scaler = torch.cuda.amp.GradScaler() を初期化（CUDA時）
forward/loss を with torch.cuda.amp.autocast(dtype=torch.float16 or bfloat16): で囲む
backward を scaler.scale(loss).backward() → scaler.step(optimizer); scaler.update()
main() 冒頭付近で
torch.set_float32_matmul_precision("high")（Ampere+）
【推定トータル効果の目安（重複を除いた現実的な範囲）】

AMP + TF32: 1.3〜2.0x
DataLoader 並列化 + 非同期転送: 1.1〜1.5x（CPU/IOがボトルネックの場合）
グラフ構築の最適化（repeat_interleave, GPU実行の徹底）: 1.05〜1.2x
torch.compile: 1.1〜1.3x
合計で1.6〜3.0x 程度の高速化が現実的（GPU/データ/ハードによる）
【補足（注意点）】

AMP導入時は学習の安定性を確認（loss scalingは自動、精度は多くの場合問題なし）。
近傍半径を削る・message passing回数を減らす等は精度とトレードオフ。まずはAMP/データパイプライン/graph構築の改善から着手がおすすめ。
torch-cluster がCUDA版で入っていないと radius_graph がCPUに落ちる可能性あり。必ずCUDA対応を確認。
この方針で進めましょうか？

まずはノイズのデバイス整合と非同期転送、batch_ids最適化を適用。
次に DataLoader 並列化とAMP/TF32を導入。
最後に必要なら torch.compile やハイパラ（mpステップ、半径）のチューニングを検討。